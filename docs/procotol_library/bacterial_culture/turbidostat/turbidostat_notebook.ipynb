{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PyLabRobot Turbidostat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "##### Purpose:\n",
    "This notebook is meant to be a comprehensive notebook for a turbidostat. \n",
    "\n",
    "\n",
    "##### Instructions:\n",
    "Currently it is in the simulation configuration, in order to set it for a real experiment:\n",
    "- change the backend\n",
    "- change the deck to the apropriate robot configuration.\n",
    "- modify the waste removal\n",
    "- modify the media renewal\n",
    "- determine SOP for water exchange (to prevent bleach accumulation in wash wells)\n",
    "- Attach PLR plate reader to 'fake' plate reader class\n",
    "\n",
    "\n",
    "##### Contents:\n",
    "- SQLite database (via SQLalchemy)\n",
    "- graphing feature for SQL data\n",
    "- three different controllers for the turbidostats:\n",
    "    - PID & k estimation control\n",
    "    - k estimation control\n",
    "    - direct proportional control\n",
    "- plate & LiquidHandler setup\n",
    "- PLR logic for turbidostat\n",
    "    - dilute_96w_plate\n",
    "    - mix\n",
    "    - wash\n",
    "- logic for cleaning tips for continous usage and no tip_switching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Required import beyond PLR/native python:\n",
    "- seaborn\n",
    "- sqlalchemy\n",
    "- numpy\n",
    "- pandas\n",
    "- sqlite3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code inn order to strip all outputs upon git add & commit\n",
    "! pip install nbstripout\n",
    "! nbstripout --install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylabrobot.liquid_handling import LiquidHandler\n",
    "from pylabrobot.liquid_handling import LiquidHandlerChatterboxBackend\n",
    "from pylabrobot.liquid_handling.backends import LiquidHandlerBackend\n",
    "from pylabrobot.visualizer.visualizer import Visualizer\n",
    "from pylabrobot.resources.opentrons import OTDeck\n",
    "from pylabrobot.resources.hamilton import HamiltonSTARDeck\n",
    "from pylabrobot.resources import Deck, Coordinate\n",
    "\n",
    "from pylabrobot.resources.opentrons.load import *\n",
    "from pylabrobot.resources.opentrons.plates import *\n",
    "from pylabrobot.resources.agenbio.plates import AGenBio_4_troughplate_75000_Vb\n",
    "\n",
    "from pylabrobot.resources.resource_stack import ResourceStack\n",
    "from pylabrobot.resources.plate import Lid\n",
    "\n",
    "\n",
    "from pylabrobot.resources import set_tip_tracking, set_volume_tracking, set_cross_contamination_tracking\n",
    "set_tip_tracking(True), set_volume_tracking(True)\n",
    "\n",
    "from pylabrobot.resources import (\n",
    "    corning_96_wellplate_360ul_flat,\n",
    "    opentrons_24_tuberack_eppendorf_2ml_safelock_snapcap,\n",
    "    opentrons_96_tiprack_300ul,\n",
    "    nest_12_reservoir_15ml,\n",
    "    nest_96_wellplate_2ml_deep,\n",
    "    corning_6_wellplate_16point8ml_flat,\n",
    "    Cor_96_wellplate_360ul_Fb,\n",
    "    Cor_96_wellplate_360ul_Fb_Lid,\n",
    ")\n",
    "\n",
    "\n",
    "# import opentrons\n",
    "import seaborn\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# For database construction & usage\n",
    "from sqlalchemy import create_engine, Column, Integer, Float, String, ForeignKey, desc, func, asc\n",
    "from sqlalchemy.orm import declarative_base, relationship, sessionmaker\n",
    "import sqlite3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cptl_alphabet = [chr(i) for i in range(65, 91)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Database with sqlalchemy (more friendly for future users/swtiching the sytem in the future.)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Plate(Base):\n",
    "    __tablename__ = 'plates'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String, unique=True, nullable=False)\n",
    "    num_rows = Column(Integer, nullable=False)\n",
    "    num_cols = Column(Integer, nullable=False)\n",
    "    readings = relationship(\"Reading\", back_populates=\"plate\")\n",
    "    wells = relationship(\"Well\", back_populates=\"plate\")\n",
    "\n",
    "\n",
    "class Well(Base):\n",
    "    __tablename__ = 'wells'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    row = Column(String, nullable=False)\n",
    "    col = Column(Integer, nullable=False)\n",
    "    readings = relationship(\"Reading\", back_populates=\"well\")\n",
    "    plate_id = Column(Integer, ForeignKey('plates.id'), nullable=False)\n",
    "    plate = relationship('Plate', back_populates='wells')\n",
    "\n",
    "\n",
    "class Reading(Base):\n",
    "    __tablename__ = 'readings'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    timestamp = Column(Float, default=lambda: time.time())  # UNIX timestamp\n",
    "    plate_id = Column(Integer, ForeignKey('plates.id'))\n",
    "    well_id = Column(Integer, ForeignKey('wells.id'))\n",
    "    od = Column(Float)\n",
    "    k_estimate = Column(Float)\n",
    "    transfer_vol_frac = Column(Float)\n",
    "\n",
    "    plate = relationship(\"Plate\", back_populates=\"readings\")\n",
    "    well = relationship(\"Well\", back_populates=\"readings\")\n",
    "\n",
    "# Create the database and session\n",
    "\n",
    "\n",
    "\n",
    "# TO reset the database for testing to save data past each run.\n",
    "# remove if data should be saved\n",
    "# TODO: will change file handling when set into production code.\n",
    "\n",
    "db_path = \"turbidostat.db\"\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "\n",
    "\n",
    "engine = create_engine(\"sqlite:///turbidostat.db\")\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_add_plate(session, plate):\n",
    "    plate_db_obj = Plate(name=plate.name, num_rows=plate.num_items_y, num_cols=plate.num_items_x)\n",
    "    session.add(plate_db_obj)\n",
    "    session.commit()\n",
    "\n",
    "\n",
    "def db_add_wells_from_plate(session, plate_name):\n",
    "    # get a plate that is a database object, not a py lab robot object\n",
    "    db_plate = session.query(Plate).filter_by(name=plate_name).first()     # there should only be 1, but this returns the actual object, not a list\n",
    "    rows = db_plate.num_rows\n",
    "    cols = db_plate.num_cols\n",
    "    for row_index in range(rows):\n",
    "        for col in range(cols):\n",
    "            session.add(Well(plate=db_plate, row=cptl_alphabet[row_index], col=col+1))\n",
    "            logging.info(f'added well to database: plate: {db_plate.name}. row, col: {cptl_alphabet[row_index]}, {col + 1}')\n",
    "    session.commit()\n",
    "    \n",
    "\n",
    "def db_add_reading(session, reading, well_row, well_col, plate_name):\n",
    "    '''\n",
    "    ENSURE WELL EXISTS BEFORE ATTEMPTING TO ADD A READING.\n",
    "\n",
    "    well_row should be an int, it is typecast to a capital letter in this function.\n",
    "    '''\n",
    "    od, k_est, transfer_vol_frac = reading\n",
    "\n",
    "    db_well = session.query(Well).join(Well.plate).filter(\n",
    "        Well.row == cptl_alphabet[well_row],\n",
    "        Well.col == well_col,\n",
    "        Plate.name == plate_name\n",
    "        ).first()\n",
    "    \n",
    "    if db_well is None:\n",
    "        logging.warning(f'Well does not exist. plate_name: {plate_name}. row, col: {cptl_alphabet[well_row]}, {well_col}')\n",
    "        logging.warning(f'Adding well to database with same characteristics.')\n",
    "        db_plate = session.query(Plate).filter_by(name=plate_name).first()\n",
    "        db_well = Well(plate=db_plate, row=cptl_alphabet[well_row], col=well_col)\n",
    "        session.add(db_well)\n",
    "\n",
    "    session.add(Reading(well=db_well,                  # ORM Well object\n",
    "        plate=db_well.plate,\n",
    "        od=od,\n",
    "        k_estimate=k_est,\n",
    "        transfer_vol_frac=transfer_vol_frac\n",
    "    ))\n",
    "    logging.info(f'added reading to db: plate: {db_well.plate.name}, (row, col): ({db_well.row}, {db_well.col}), od: {od}, k_est: {k_est}, transfer_vol_frac: {transfer_vol_frac}')\n",
    "\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Set up the Deck and Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_lh() -> LiquidHandler:\n",
    "    lh = LiquidHandler(backend=LiquidHandlerChatterboxBackend(), deck=OTDeck())\n",
    "\n",
    "    await lh.setup()\n",
    "\n",
    "    vis = Visualizer(resource=lh)\n",
    "    await vis.setup()\n",
    "    return lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "'num_rails', 'size_x', 'size_y', and 'size_z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Add labware to the deck\n",
    "\n",
    "* 1 culture plates (corning 96 well plates)\n",
    "* 1 tip racks\n",
    "* 3 media plates (deep well plates)\n",
    "* Plate position for reader tray\n",
    "* Wash positions (single-channel waste, bleach, 4 waters)\n",
    "\n",
    "You may need to create custom definitions for the media plates and wash positions (we can go over this)\n",
    "\n",
    "The OT-2 only has 9 positions but we will have at least 12 for the ***** system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def deck_setup(lh: LiquidHandler, fill=True) -> list:\n",
    "    # Declare a tip rack object - using opentrons for right now.\n",
    "    tip_rack_0 =  opentrons_96_tiprack_300ul(\"tip_rack_0\")\n",
    "    tip_rack_1 =  opentrons_96_tiprack_300ul(\"tip_rack_1\")\n",
    "\n",
    "    # Assign the tip rack to spot 1\n",
    "    lh.deck.assign_child_at_slot(tip_rack_0, 7)\n",
    "    lh.deck.assign_child_at_slot(tip_rack_1, 8)\n",
    "\n",
    "    tip_racks = [tip_rack_0, tip_rack_1]\n",
    "\n",
    "    # Declare a plate object\n",
    "    culture_plate_0 =  Cor_96_wellplate_360ul_Fb(\"culture_plate_0\", with_lid=False)\n",
    "    culture_plate_1 =  Cor_96_wellplate_360ul_Fb(\"culture_plate_1\", with_lid=False)\n",
    "\n",
    "    culture_plates = [\n",
    "        culture_plate_0,\n",
    "        culture_plate_1,\n",
    "    ]\n",
    "\n",
    "\n",
    "    # bleach plate /w water to rinse to ensure residual bacteria in tips are cleaned\n",
    "    wash = AGenBio_4_troughplate_75000_Vb('wash')\n",
    "    lh.deck.assign_child_at_slot(wash, 9)\n",
    "\n",
    "    # instantiate media plates w/ lids & add to deck\n",
    "    media_plates = [\n",
    "        Cor_96_wellplate_360ul_Fb(f\"media_plate_{i}\", with_lid=False) for i in range(4)\n",
    "    ]\n",
    "\n",
    "\n",
    "    # for visualization purposes, ensure filling of tubes, set properly\n",
    "    # ================================\n",
    "\n",
    "    # fill all tubes w/ various fludids \n",
    "    if fill:\n",
    "        for j in range(1, 13):\n",
    "            for i in range(8):\n",
    "                # Using the f-string allows us to iterate through \n",
    "                # wells A1 -> B1 -> C1 -> ... -> H1\n",
    "                # all in one line of code!\n",
    "                \n",
    "                # set arbitrary volume for culture plates\n",
    "                for media_plate in media_plates:\n",
    "                    media_plate[f'{cptl_alphabet[i]}{j}'][0].tracker.set_liquids([(\"media\", 300)])\n",
    "                culture_plate_1[f'{cptl_alphabet[i]}{j}'][0].tracker.set_liquids([(\"culture_1\", 150)])\n",
    "                culture_plate_0[f'{cptl_alphabet[i]}{j}'][0].tracker.set_liquids([(\"culture_0\", 150)])\n",
    "\n",
    "\n",
    "\n",
    "        wash['A1'][0].tracker.set_liquids([('waste', 0)])\n",
    "        wash['A2'][0].tracker.set_liquids([('bleach', 30000)])\n",
    "        wash['A3'][0].tracker.set_liquids([('water', 30000)])\n",
    "        wash['A4'][0].tracker.set_liquids([('waste', 30000)])\n",
    "\n",
    "\n",
    "    # ================================\n",
    "\n",
    "    return tip_racks, wash, media_plates, culture_plates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lid stacking for each of the media plates\n",
    "\n",
    "def setup_stacks(media_plates, culture_plates, lh: LiquidHandler, media_slots=None, culture_slots=None):\n",
    "    '''\n",
    "    ALSO adds lids to each container as part of the stack not an attribute of the plates themselves\n",
    "    '''\n",
    "\n",
    "    if media_slots is None:\n",
    "        media_slots = [i for i in range(1,5)]\n",
    "    \n",
    "    if culture_slots is None:\n",
    "        culture_slots = [5, 6]\n",
    "\n",
    "    media_stacks = []\n",
    "\n",
    "    for i, media_plate in enumerate(media_plates):\n",
    "        media_stacks.append(ResourceStack(name=f'media_stack_{i}', direction='z', resources=[media_plate]))\n",
    "        lh.deck.assign_child_at_slot(media_stacks[i], media_slots[i])\n",
    "    \n",
    "    culture_stacks = []\n",
    "\n",
    "    for i, culture_plate in enumerate(culture_plates):\n",
    "        culture_stacks.append(ResourceStack(name=f'culture_stack_{i}', direction='z', resources=[culture_plate]))\n",
    "        lh.deck.assign_child_at_slot(culture_stacks[i], culture_slots[i])\n",
    "    \n",
    "    return media_stacks, culture_stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlateReader:\n",
    "    def __init__(self, is_sim, output_file=None, session=None, data_sim=None):\n",
    "        self.is_sim = is_sim\n",
    "        self.output_file = output_file\n",
    "        self.session = session\n",
    "        self.data_sim = data_sim\n",
    "\n",
    "        # self.PLR_pr = ... etc.\n",
    "        # configure to attach to a PLR plate reader, save as an instance variable\n",
    "\n",
    "    def aquire_data(self, plate_stack, mean_absorbance=0.5, std_dev=0.1, timedelta=0):\n",
    "        '''\n",
    "        If simulation, simulate data, else, call the plate reader and read the plate. returns the filename where the .csv result from the plate reader returns\n",
    "\n",
    "\n",
    "        '''\n",
    "        plate = plate_stack.children[0]\n",
    "        # Get rows and columns from the plate\n",
    "        if self.is_sim:\n",
    "            self.data_sim.generate_data(bac_plate=plate, output_file=self.output_file)\n",
    "\n",
    "        # not a simulation\n",
    "        else:\n",
    "            # gripper.move_labware(labware=plate, dest_spot=)\n",
    "            # PLR Plate reader call\n",
    "            # dont use the sim_data/ directory, just use the output file and re-write all of the data.\n",
    "            # get the data and pass int .csv, return the filename\n",
    "            pass\n",
    "\n",
    "    def get_output_file(self):\n",
    "        return self.output_file\n",
    "\n",
    "    def get_index(self):\n",
    "        return self.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSimulator:\n",
    "    def __init__(self, session=None, rand_nor_mean=1, rand_nor_std=0.05):\n",
    "        self.session = session \n",
    "        self.rand_nor_mean = rand_nor_mean\n",
    "        self.rand_nor_std = rand_nor_std\n",
    "\n",
    "\n",
    "    def generate_data(self, bac_plate, output_file):\n",
    "        ''' \n",
    "        Assuming that output_file already has a .csv file-extension on it, so that it does not need to  \n",
    "        '''\n",
    "        rows = bac_plate.num_items_y\n",
    "        cols = bac_plate.num_items_x\n",
    "        self.output_file = output_file\n",
    "\n",
    "        data = []\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                if self.session:\n",
    "                    # get the last reading object for this cell\n",
    "                    last_reading = self.session.query(Reading).join(Reading.well).join(Well.plate).filter(\n",
    "                        Plate.name == bac_plate.name,\n",
    "                        Well.col == col + 1,\n",
    "                        Well.row == cptl_alphabet[row],\n",
    "                    ).order_by(desc(Reading.timestamp)).first()\n",
    "                    if last_reading:\n",
    "                        last_od = last_reading.od\n",
    "\n",
    "                        # dilution step, since OD ~= bact. conc., then M1V1 = M2V2\n",
    "                        dilution_factor = last_reading.transfer_vol_frac\n",
    "                        \n",
    "                        last_od = ((last_od * 1)/(1 + dilution_factor))\n",
    "\n",
    "                        # hard code value for simulation\n",
    "                        randomization_factor = np.random.normal(\n",
    "                            loc=self.rand_nor_mean, scale=self.rand_nor_std)\n",
    "\n",
    "                        # if last_od <= 0:\n",
    "                        #     logging.critical(f'od registed as negative (od: {last_od}), reverted to 0.1 info: plate: {plate.name}, well coords: {cptl_alphabet[row]}{col+1}')\n",
    "                        #     last_od = 0.1\n",
    "\n",
    "                        dt = 1200\n",
    "                        k = last_reading.k_estimate\n",
    "                        absorbance_value = last_od * np.exp((dt/3600)*k) * randomization_factor\n",
    "                    else:\n",
    "                        absorbance_value = max(np.random.normal(loc=self.rand_nor_mean, scale=self.rand_nor_std), 0.1)\n",
    "\n",
    "                    # additional perturbation for sim testing\n",
    "                    # if 30 <= self.index <= 60: \n",
    "                    #     absorbance_value = absorbance_value * 1.3\n",
    "                data.append(absorbance_value)\n",
    "\n",
    "        self.format_csv(measurements=data, output_file=output_file)\n",
    "\n",
    "    def format_csv(self, measurements, output_file):\n",
    "        test_name = 'Testname: test_001'\n",
    "        date = \"Date: 5/26/2025 Time: 4:38:44 PM (UTC--4)\"\n",
    "        id = 'ID1: sample_plate_0 ID2: - ID3: 0x33741382a'\n",
    "        channels = 'No. of Channels / Multichromatics: 1'\n",
    "        cycles = 'No. of Cycles: 1'\n",
    "        end = 'End_of_header'\n",
    "\n",
    "        chromatic = \"Chromatic: 1\"\n",
    "        cycle = \"Cycle: 1\"\n",
    "\n",
    "\n",
    "        output = [test_name, date, id, channels, cycles, end, \"\", chromatic, cycle]\n",
    "        for i in range(8):\n",
    "            print(cptl_alphabet[i])\n",
    "            for j in range(1, 13):\n",
    "                if len(str(j)) == 1:\n",
    "                    well = cptl_alphabet[i] + '0' + str(j)\n",
    "                else:\n",
    "                    well = cptl_alphabet[i] + str(j)\n",
    "                well = well + f': {measurements[i*12 + j - 1]}'\n",
    "                output.append(well)\n",
    "\n",
    "        df = pd.DataFrame(output)\n",
    "        df.to_csv(output_file)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurbController(object):\n",
    "    id_counter = 0\n",
    "\n",
    "    def __init__(self, setpoint=0.0, init_od=1e-6, output_limits=(0, 0.5), db_session=None):\n",
    "        self.output_limits = output_limits       # TODO: adjust for valid values, such as the max of the 96 well plate, make it a variable\n",
    "        self.setpoint = setpoint\n",
    "        self.od = init_od\n",
    "        self.state = {'update_time': time.time(), 'od':init_od}\n",
    "        self.state_history = [self.state]\n",
    "        self.name = str(self.id_counter)\n",
    "        self.__class__.id_counter += 1\n",
    "        self.ever_updated = False\n",
    "        self.db_session = db_session\n",
    "\n",
    "    def step(self, delta_time=None, od_meas=None, last_transfer_vol_frac=None):\n",
    "        if delta_time is None:  # use real time\n",
    "            self.state = {'update_time': time.time()}\n",
    "        else:\n",
    "            self.state = {'update_time': self._last_time() + delta_time}\n",
    "        delta_time = self.state['update_time'] - self._last_time()\n",
    "        transfer_vol_frac = self._step(\n",
    "            delta_time, od_meas, last_transfer_vol_frac)\n",
    "        # limit output\n",
    "        min_out, max_out = self.output_limits\n",
    "        transfer_vol_frac = min(max_out, max(min_out, transfer_vol_frac))\n",
    "        self.state.update(\n",
    "            {'od': self.od, 'delta_time': delta_time, 'output': transfer_vol_frac})\n",
    "        self.state_history.append(self.state)\n",
    "        self.ever_updated = True\n",
    "        return transfer_vol_frac\n",
    "\n",
    "    def _last_time(self):\n",
    "        return self.state_history[-1]['update_time']\n",
    "    \n",
    "    def history(self):\n",
    "        # omit initial state\n",
    "        return self.state_history[1:] if self.state_history else []\n",
    "\n",
    "    def last_known_od(self):\n",
    "        last_state = self.state_history[-1]\n",
    "        return last_state.get('od', self.od)\n",
    "\n",
    "    def last_known_output(self):\n",
    "        last_state = self.state_history[-1]\n",
    "        return last_state.get('output', 0)\n",
    "\n",
    "    def scrape_history(self, key, fill_value=None):\n",
    "        return [state.get(key, fill_value) for state in self.history()]\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.step(*args, **kwargs)  # default to real time\n",
    "\n",
    "    def save(self, save_dir='controller_history', filename=None):\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        if not os.path.isdir(save_dir):\n",
    "            raise ValueError('Controller save directory is not a directory')\n",
    "        if filename is None:\n",
    "            filename = self.name + '.turbhistory'\n",
    "        path = os.path.join(save_dir, filename)\n",
    "        with open(path, 'w+') as f:\n",
    "            f.write(json.dumps(self.state_history))\n",
    "\n",
    "    def load(self, from_dir='controller_history', filename=None):\n",
    "        if filename is None:\n",
    "            # go get the one with this one's name from before\n",
    "            filename = self.name + '.turbhistory'\n",
    "        path = os.path.join(from_dir, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            raise ValueError('No controller save history found at ' + path)\n",
    "        with open(path) as f:\n",
    "            self.state_history = json.loads(f.read())\n",
    "        self.ever_updated = False\n",
    "\n",
    "\n",
    "class ParamEstTurbCtrlr(TurbController):\n",
    "    def __init__(self, setpoint=0.7, init_od=1e-6, init_k=None, output_limits=(0, 180), db_session=None):\n",
    "        super(ParamEstTurbCtrlr, self).__init__(setpoint, init_od, output_limits=output_limits, db_session=db_session)\n",
    "        self.default_k = .5\n",
    "        if init_k is None:\n",
    "            init_k = self.default_k\n",
    "        self.k_estimate = init_k\n",
    "        self.state.update({'k_estimate': init_k})\n",
    "        self.k_limits = .05, 3\n",
    "        self.plate = 'None'\n",
    "        self.well_id = 'No ID'\n",
    "\n",
    "    def predict_od(self, od_now, transfer_vol_frac, dt, k):\n",
    "        # delta time (dt) is in seconds, k is in hr^-1\n",
    "        logging.info(\"debug od_now\")\n",
    "        logging.info(od_now)\n",
    "        logging.info(\"debug dt\")\n",
    "        logging.info(dt)\n",
    "        logging.info(\"debug k\")\n",
    "        logging.info(k)\n",
    "        logging.info(\"debug transfer vol frac\")\n",
    "        logging.info(transfer_vol_frac)\n",
    "        return od_now*np.exp(dt/3600*k)/(1+transfer_vol_frac)\n",
    "\n",
    "    def infer_k(self, od_then, transfer_vol_frac, od_now, dt):\n",
    "        '''\n",
    "        Predicts the OD, where od_now refers to the last known OD, whereas od_then refers to the last\n",
    "        known od, before the current measurement was taken.\n",
    "        '''\n",
    "        min_k, max_k = self.k_limits\n",
    "        logging.info(\"infer k calculation parameters\")\n",
    "        logging.info(transfer_vol_frac)\n",
    "        logging.info(transfer_vol_frac)\n",
    "        logging.info(od_now)\n",
    "        logging.info(od_then)\n",
    "        logging.info(dt)\n",
    "        logging.info(\"end infer k parameters\")\n",
    "        return max(min_k, min(max_k, np.log((transfer_vol_frac + 1)*od_now/od_then)/dt*3600))\n",
    "\n",
    "    def last_known_k(self):\n",
    "        last_state = self.state_history[-1]\n",
    "        return last_state.get('k_estimate', self.default_k)\n",
    "\n",
    "    def _step(self, delta_time, od_meas, last_transfer_frac=None):\n",
    "        prior_od = self.last_known_od()\n",
    "        last_known_out = self.last_known_output()\n",
    "        prior_k = self.last_known_k()\n",
    "        last_state = self.state_history[-1]\n",
    "        prior_out = last_known_out if last_transfer_frac is None else last_transfer_frac\n",
    "        if od_meas is not None:\n",
    "            prediction = self.predict_od(\n",
    "                prior_od, prior_out, delta_time, prior_k)\n",
    "            # max(prediction - .05, min(prediction + .05, od_meas)) # clamp based on prediction to rule out crazy readings\n",
    "            self.od = od_meas\n",
    "        # error = self.predict_od(prior_od, prior_out, delta_time, prior_k) - od_meas\n",
    "        if self.ever_updated:  # only sensible to infer k after more than one point\n",
    "            s = .15\n",
    "            self.k_estimate = prior_k*(1-s) + self.infer_k(prior_od, prior_out,\n",
    "                                                           self.od, delta_time)*s\n",
    "            # try to close a fraction of the distance to the correct volume per iteration\n",
    "            # use model to solve for perfect transfer volume, which may not be achievable\n",
    "            s = .7\n",
    "            transfer_vol_frac = (self.od*np.exp(delta_time/3600*self.k_estimate)\n",
    "                                 / ((self.setpoint*s + prior_od*(1-s))) - 1)\n",
    "        else:\n",
    "            # play it safe\n",
    "            self.k_estimate = prior_k\n",
    "            transfer_vol_frac = prior_out\n",
    "        # limit output\n",
    "        min_out, max_out = self.output_limits\n",
    "        transfer_vol_frac = min(max_out, max(min_out, transfer_vol_frac))\n",
    "        self.state.update({'k_estimate': self.k_estimate})\n",
    "        return transfer_vol_frac\n",
    "\n",
    "    def set_od(self, od):\n",
    "        self.od = od\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosticPIDTurbController(TurbController):\n",
    "    def __init__(self, setpoint=0.7, init_od=1e-6, kp=1.0, ki=0.1, kd=0.05, \n",
    "                 output_limits=(0, 2), db_session=None, well_id=\"unknown\"):\n",
    "        \"\"\"\n",
    "        Diagnostic PID-based turbidostat controller with extensive logging.\n",
    "        \"\"\"\n",
    "        super(DiagnosticPIDTurbController, self).__init__(setpoint, init_od, output_limits=output_limits, db_session=db_session)\n",
    "        \n",
    "        # PID parameters\n",
    "        self.kp = kp\n",
    "        self.ki = ki\n",
    "        self.kd = kd\n",
    "        \n",
    "        # PID state variables\n",
    "        self.integral = 0.0\n",
    "        self.previous_error = 0.0\n",
    "        self.previous_time = None\n",
    "        \n",
    "        # Integral windup prevention\n",
    "        self.integral_limits = (-5.0, 5.0)\n",
    "        \n",
    "        # Growth rate estimation\n",
    "        # init_k = np.linspace(0.1, 3.0, 96*2)\n",
    "        self.estimated_growth_rate = .5#  init_k[self.id_counter-1]  # hr^-1\n",
    "        self.growth_rate_history = []\n",
    "        \n",
    "        # Diagnostic tracking\n",
    "        self.well_id = well_id\n",
    "        self.step_count = 0\n",
    "        self.convergence_threshold = 0.05  # Within 5% of setpoint\n",
    "        self.converged_steps = 0\n",
    "        self.diagnostic_log = []\n",
    "        \n",
    "        # Add PID parameters to initial state\n",
    "        self.state.update({\n",
    "            'kp': kp, 'ki': ki, 'kd': kd,\n",
    "            'integral': self.integral,\n",
    "            'previous_error': self.previous_error,\n",
    "            'estimated_growth_rate': self.estimated_growth_rate,\n",
    "            'well_id': self.well_id\n",
    "        })\n",
    "\n",
    "    def _estimate_growth_rate(self, od_prev, od_current, dt_hours, prev_transfer_frac):\n",
    "        \"\"\"Estimate growth rate with diagnostic logging\"\"\"\n",
    "        if dt_hours <= 0 or od_prev <= 0:\n",
    "            return self.estimated_growth_rate\n",
    "        \n",
    "        # Account for dilution\n",
    "        od_after_dilution = od_prev / (1 + prev_transfer_frac)\n",
    "        \n",
    "        if od_after_dilution > 0:\n",
    "            try:\n",
    "                k_apparent = np.log(od_current / od_after_dilution) / dt_hours\n",
    "                k_apparent = max(0, min(3.0, k_apparent))\n",
    "                \n",
    "                self.growth_rate_history.append(k_apparent)\n",
    "                if len(self.growth_rate_history) > 10:\n",
    "                    self.growth_rate_history.pop(0)\n",
    "                \n",
    "                old_rate = self.estimated_growth_rate\n",
    "                self.estimated_growth_rate = np.mean(self.growth_rate_history)\n",
    "                \n",
    "                # Log significant changes in growth rate\n",
    "                if abs(self.estimated_growth_rate - old_rate) > 0.1:\n",
    "                    print(f\"Well {self.well_id}: Growth rate changed from {old_rate:.3f} to {self.estimated_growth_rate:.3f}\")\n",
    "                \n",
    "            except (ValueError, ZeroDivisionError):\n",
    "                print(f\"Well {self.well_id}: Error calculating growth rate\")\n",
    "        \n",
    "        return self.estimated_growth_rate\n",
    "\n",
    "    def _calculate_steady_state_transfer(self, current_od, target_od, dt_hours):\n",
    "        \"\"\"Calculate steady-state transfer with bounds checking\"\"\"\n",
    "        if dt_hours <= 0:\n",
    "            return 0\n",
    "        \n",
    "        growth_factor = np.exp(self.estimated_growth_rate * dt_hours)\n",
    "        steady_state_transfer = growth_factor - 1\n",
    "        \n",
    "        # Error-based correction\n",
    "        error = current_od - target_od\n",
    "        error_correction = error / target_od if target_od > 0 else 0\n",
    "        \n",
    "        corrected_transfer = steady_state_transfer + error_correction\n",
    "        \n",
    "        return max(0, corrected_transfer)\n",
    "\n",
    "    def _step(self, delta_time, od_meas, last_transfer_frac=None):\n",
    "        \"\"\"Enhanced _step with comprehensive diagnostics\"\"\"\n",
    "        self.step_count += 1\n",
    "        prev_od = self.od\n",
    "        \n",
    "        # Update OD measurement\n",
    "        if od_meas is not None:\n",
    "            self.od = od_meas\n",
    "        \n",
    "        # Time calculations\n",
    "        dt_hours = delta_time / 3600.0\n",
    "        \n",
    "        # Growth rate estimation\n",
    "        if last_transfer_frac is not None and self.ever_updated:\n",
    "            self._estimate_growth_rate(prev_od, self.od, dt_hours, last_transfer_frac)\n",
    "        \n",
    "        # Calculate error\n",
    "        error = self.od - self.setpoint\n",
    "        error_percent = (error / self.setpoint) * 100 if self.setpoint > 0 else 0\n",
    "        \n",
    "        # Track convergence\n",
    "        if abs(error_percent) < self.convergence_threshold * 100:\n",
    "            self.converged_steps += 1\n",
    "        else:\n",
    "            self.converged_steps = 0\n",
    "            \n",
    "        # PID calculations\n",
    "        proportional = self.kp * error\n",
    "        \n",
    "        # Integral with windup protection\n",
    "        if dt_hours > 0:\n",
    "            self.integral += error * dt_hours\n",
    "            min_int, max_int = self.integral_limits\n",
    "            was_clamped = False\n",
    "            if self.integral < min_int or self.integral > max_int:\n",
    "                was_clamped = True\n",
    "            self.integral = max(min_int, min(max_int, self.integral))\n",
    "        integral_term = self.ki * self.integral\n",
    "        \n",
    "        # Derivative\n",
    "        if self.previous_time is not None and dt_hours > 0:\n",
    "            derivative = (error - self.previous_error) / dt_hours\n",
    "        else:\n",
    "            derivative = 0.0\n",
    "        derivative_term = self.kd * derivative\n",
    "        \n",
    "        # PID correction\n",
    "        pid_correction = proportional + integral_term + derivative_term\n",
    "        \n",
    "        # Feed-forward\n",
    "        feedforward_transfer = self._calculate_steady_state_transfer(\n",
    "            self.od, self.setpoint, dt_hours)\n",
    "        \n",
    "        # Final transfer calculation\n",
    "        pid_scaled = pid_correction * 0.1\n",
    "        transfer_vol_frac = feedforward_transfer + pid_scaled\n",
    "        transfer_vol_frac = max(0, transfer_vol_frac)\n",
    "        \n",
    "        # Check for saturation\n",
    "        min_out, max_out = self.output_limits\n",
    "        was_saturated = transfer_vol_frac > max_out or transfer_vol_frac < min_out\n",
    "        transfer_vol_frac_clamped = min(max_out, max(min_out, transfer_vol_frac))\n",
    "        \n",
    "        # Store diagnostic information\n",
    "        diagnostic_info = {\n",
    "            'step': self.step_count,\n",
    "            'well_id': self.well_id,\n",
    "            'od': self.od,\n",
    "            'setpoint': self.setpoint,\n",
    "            'error': error,\n",
    "            'error_percent': error_percent,\n",
    "            'dt_hours': dt_hours,\n",
    "            'growth_rate': self.estimated_growth_rate,\n",
    "            'proportional': proportional,\n",
    "            'integral': self.integral,\n",
    "            'integral_term': integral_term,\n",
    "            'derivative_term': derivative_term,\n",
    "            'pid_correction': pid_correction,\n",
    "            'feedforward': feedforward_transfer,\n",
    "            'transfer_calculated': transfer_vol_frac,\n",
    "            'transfer_final': transfer_vol_frac_clamped,\n",
    "            'was_saturated': was_saturated,\n",
    "            'integral_clamped': was_clamped if 'was_clamped' in locals() else False,\n",
    "            'converged_steps': self.converged_steps\n",
    "        }\n",
    "        \n",
    "        self.diagnostic_log.append(diagnostic_info)\n",
    "        \n",
    "        # Print diagnostics for problematic cases\n",
    "        if self.step_count % 10 == 0 or abs(error_percent) > 20:  # Every 10 steps or large error\n",
    "            print(f\"Well {self.well_id} Step {self.step_count}:\")\n",
    "            print(f\"  OD: {self.od:.3f} (target: {self.setpoint:.3f}), Error: {error_percent:.1f}%\")\n",
    "            print(f\"  Growth rate: {self.estimated_growth_rate:.3f} hr⁻¹\")\n",
    "            print(f\"  PID components - P: {proportional:.4f}, I: {integral_term:.4f}, D: {derivative_term:.4f}\")\n",
    "            print(f\"  Feed-forward: {feedforward_transfer:.4f}, Final transfer: {transfer_vol_frac_clamped:.4f}\")\n",
    "            if was_saturated:\n",
    "                print(f\"  WARNING: Output saturated! Calculated: {transfer_vol_frac:.4f}, Limits: {self.output_limits}\")\n",
    "            if was_clamped if 'was_clamped' in locals() else False:\n",
    "                print(f\"  WARNING: Integral clamped! Value: {self.integral:.4f}, Limits: {self.integral_limits}\")\n",
    "            print()\n",
    "        \n",
    "        # Update state\n",
    "        self.previous_error = error\n",
    "        self.previous_time = self.state.get('update_time', time.time())\n",
    "        \n",
    "        self.state.update({\n",
    "            'error': error,\n",
    "            'proportional': proportional,\n",
    "            'integral': self.integral,\n",
    "            'integral_term': integral_term,\n",
    "            'derivative': derivative,\n",
    "            'derivative_term': derivative_term,\n",
    "            'pid_correction': pid_correction,\n",
    "            'feedforward_transfer': feedforward_transfer,\n",
    "            'estimated_growth_rate': self.estimated_growth_rate,\n",
    "            'final_transfer': transfer_vol_frac_clamped,\n",
    "            'step_count': self.step_count\n",
    "        })\n",
    "        \n",
    "        return transfer_vol_frac_clamped\n",
    "\n",
    "    def get_diagnostic_summary(self):\n",
    "        \"\"\"Return summary of controller performance\"\"\"\n",
    "        if not self.diagnostic_log:\n",
    "            return \"No diagnostic data available\"\n",
    "        \n",
    "        recent_errors = [abs(log['error_percent']) for log in self.diagnostic_log[-10:]]\n",
    "        avg_recent_error = np.mean(recent_errors)\n",
    "        \n",
    "        saturated_steps = sum(1 for log in self.diagnostic_log if log['was_saturated'])\n",
    "        saturation_rate = saturated_steps / len(self.diagnostic_log) * 100\n",
    "        \n",
    "        return {\n",
    "            'well_id': self.well_id,\n",
    "            'total_steps': self.step_count,\n",
    "            'current_od': self.od,\n",
    "            'current_error_percent': recent_errors[-1] if recent_errors else 0,\n",
    "            'avg_recent_error_percent': avg_recent_error,\n",
    "            'converged_steps': self.converged_steps,\n",
    "            'saturation_rate_percent': saturation_rate,\n",
    "            'estimated_growth_rate': self.estimated_growth_rate,\n",
    "            'final_integral': self.integral\n",
    "        }\n",
    "\n",
    "    def export_diagnostic_log(self, filename=None):\n",
    "        \"\"\"Export diagnostic log to CSV for analysis\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"pid_diagnostics_well_{self.well_id}.csv\"\n",
    "        \n",
    "        df = pd.DataFrame(self.diagnostic_log)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Diagnostic log exported to {filename}\")\n",
    "        \n",
    "    # Include all the other methods from the previous implementation\n",
    "    def reset_pid(self):\n",
    "        self.integral = 0.0\n",
    "        self.previous_error = 0.0\n",
    "        self.previous_time = None\n",
    "        self.growth_rate_history = []\n",
    "        self.step_count = 0\n",
    "        self.converged_steps = 0\n",
    "        self.diagnostic_log = []\n",
    "\n",
    "    def manual_tune_conservative(self):\n",
    "        self.kp = 2.0\n",
    "        self.ki = 0.5\n",
    "        self.kd = 0.1\n",
    "        \n",
    "    def set_od(self, od):\n",
    "        self.od = od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mix(lh, plate, cycles, volume, positions):\n",
    "    '''\n",
    "    Mixes a plate at up to 8 positions for a certain number of cycles, for a certain volume,\n",
    "    assumes that there are already 8 tips on machine head.\n",
    "    '''\n",
    "    for _ in range(cycles):\n",
    "        await lh.aspirate(plate[positions], vols=(volume))\n",
    "        await lh.dispense(plate[positions], vols=(volume))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def clean_tips(lh, wash):\n",
    "    '''\n",
    "    Assumes that the lh, has 8 dirty tips that are currently attached to the head of the machine\n",
    "    will run through the cleaning process with 2x bleach washes, then as many water washes as there are water_plates\n",
    "\n",
    "\n",
    "    This method also impliments a wait to allow excess liquid to drip, as well as air blowout to ensure that no liquid \n",
    "    makes its way up into the tips\n",
    "    '''\n",
    "    for i in range(2):\n",
    "        await lh.aspirate(wash['A2']*8, vols=[200]*8)\n",
    "        await lh.dispense(wash['A2']*8, vols=[200]*8)\n",
    "\n",
    "    for i in range(3,5):\n",
    "        await lh.aspirate(wash[f'A{i}']*8, vols=[200]*8)\n",
    "        await lh.dispense(wash[f'A{i}']*8, vols=[200]*8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def dilute_96w_plate(cycle_idx, replacement_volumes, tip_rack, plate_stack: ResourceStack, plate_lid_loc: ResourceStack, media_stack: ResourceStack, media_lid_loc: ResourceStack, lh, wash, cols_of_none):\n",
    "    '''\n",
    "    Removes lids of the designated culture plate and media plate, dilutes the given bacterial plate (all cols minus the cols_of_none (which empty columns). after diluting each column, clean the tips to ensure no bacterial well hopping or media contamination.)\n",
    "    '''\n",
    "    \n",
    "    # remove the lid on top of the plate to the other plate,\n",
    "    # await lh.move_lid(lid=plate_stack.get_top_item(), to=plate_lid_loc)\n",
    "\n",
    "    # remove the media lid to the top of the other media container\n",
    "    # await lh.move_lid(lid=media_stack.get_top_item(), to=media_lid_loc)\n",
    "    \n",
    "    plate = plate_stack.get_top_item()\n",
    "    media = media_stack.get_top_item()\n",
    "\n",
    "    for col_num in range(12 - cols_of_none):\n",
    "        array_idxs = [col_num*8 + i for i in range(8)]  # set the indexes for the replacement volumes & plates\n",
    "        \n",
    "        # want to get volumes first, to determine if picking up tips is needed for partially full plates\n",
    "        volumes = [replacement_volumes[array_idxs[i]] for i in range(8)]\n",
    "\n",
    "        for i in range(8):\n",
    "            if volumes[i] is None:\n",
    "                volumes[i] = 0\n",
    "    \n",
    "        positions = [f'{cptl_alphabet[i]}{col_num+1}' for i in range(8)]\n",
    "        await lh.pick_up_tips(tip_rack[positions])\n",
    "\n",
    "        # aspirate media from media reservoir\n",
    "        await lh.aspirate(media[positions], vols=volumes)\n",
    "\n",
    "        # dispense into the culture plate\n",
    "        await lh.dispense(plate[positions], vols=volumes)\n",
    "\n",
    "        # mix the bacterial colonies \n",
    "        await mix(cycles=2, plate=plate, positions=positions, volume=volumes, lh=lh)\n",
    "\n",
    "        await lh.aspirate(plate[positions], vols=volumes)\n",
    "\n",
    "        # now to dispense the spent media (with bacteria) into waste\n",
    "        await lh.dispense(wash['A1']*8, vols=volumes)\n",
    "\n",
    "        # cleaning proceedure\n",
    "        await clean_tips(lh=lh, wash=wash)\n",
    "\n",
    "\n",
    "        # drop clean tips back into rack\n",
    "        await lh.drop_tips(tip_spots=tip_rack[positions], use_channels=[i for i in range(8)])\n",
    "\n",
    "    # add the lids back to the culture and media plates respectivly.\n",
    "    # await lh.move_lid(lid=media_lid_loc.get_top_item(), to=media_stack)\n",
    "    # await lh.move_lid(lid=plate_lid_loc.get_top_item(), to=plate_stack)\n",
    "\n",
    "    \n",
    "def read_plate(plate_stack, plate_reader, is_sim):\n",
    "    '''\n",
    "    Reads data from the supplied plate reader and then returns the an array of values; oriented columnwise.\n",
    "    '''\n",
    "    # Return fake data that matches the format of the real data (ie using PlateData format)\n",
    "    plate_reader.aquire_data(plate_stack=plate_stack)\n",
    "\n",
    "    if is_sim:\n",
    "        fname = 'data.csv'\n",
    "        df = pd.read_csv(fname, index_col=0, skiprows=9)\n",
    "    else:\n",
    "        fname = plate_reader.get_output_file()\n",
    "\n",
    "    plate_data = []\n",
    "    for col in df.columns:\n",
    "        plate_data.extend(df[col].tolist())\n",
    "    plate_data = [float(val[5:]) if str(val).lower() != 'nan' or val is not None else 0.0 for val in plate_data]\n",
    "\n",
    "    return plate_data\n",
    "    \n",
    "\n",
    "def calculate_concentrations_from_od(plate_data_od, slope, intercept):\n",
    "    '''\n",
    "    Converts all values in the plate_data_od (a 1D list) into concentration values\n",
    "    based on the slope and interccept provided.\n",
    "    '''\n",
    "    \n",
    "    for od in plate_data_od:\n",
    "        concentration = od * slope + intercept\n",
    "        od = concentration\n",
    "\n",
    "    return plate_data_od\n",
    "\n",
    "\n",
    "def set_standard_curve_params(known_conc, absorbances):\n",
    "    '''\n",
    "    Completes a linear regression to establish a concentration based on the OD. \n",
    "\n",
    "    returns the calculated intercept and slope.\n",
    "    '''\n",
    "    n = len(known_conc)\n",
    "    if n != len(absorbances):\n",
    "        raise IndexError('lists (absorbances, known concentrations) must have the same length')\n",
    "    \n",
    "    intercept, slope = np.linalg.lstsq(absorbances, known_conc, rcond=None)[0]\n",
    "\n",
    "    return intercept, slope\n",
    "\n",
    "\n",
    "def calculate_replacement_volumes(turb_controller_batch, plate_data, slope, intercept, well_volume, max_well_volume, cols_of_none):\n",
    "    # Call the step function of each controller in the batch and return a list of replacement volumes\n",
    "\n",
    "    # now plate data is a columnwise list of data for each of the wells.\n",
    "    # dt of 1200 is 20 mins (1200 seconds)\n",
    "\n",
    "    max_frac = (max_well_volume - well_volume) / well_volume\n",
    "    flow_rates = [controller(od_meas=reading, delta_time=1200) for controller, reading in zip(turb_controller_batch, plate_data)]        # step (__call__()) all controllers\n",
    "    \n",
    "    print(f'flow rates: {flow_rates}')\n",
    "    \n",
    "    # ensure that dilutions don't overfill cells: max volume -> 300 µL\n",
    "\n",
    "    replacement_volumes = []\n",
    "    for frac in flow_rates:\n",
    "        frac = min(max_frac, frac)\n",
    "        replacement_volumes.append(frac)\n",
    "\n",
    "\n",
    "    return replacement_volumes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_channels_tip_origin(lh):\n",
    "    # Prints the origin location of all tips currently on the robot\n",
    "    cur_pipetter = lh.head\n",
    "\n",
    "    for channel in cur_pipetter:\n",
    "        print(f\"Channel {channel}:\")\n",
    "\n",
    "        tip_tracker = lh.head[channel]\n",
    "        \n",
    "        if tip_tracker.has_tip == True:\n",
    "            print(tip_tracker.get_tip_origin())\n",
    "        else:\n",
    "            print(\"No tip present.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def refill_media(media_stack, lid_loc, lh):    \n",
    "    if isinstance(media_stack.get_top_item(), Lid):\n",
    "        await lh.move_lid(lid=media_stack.get_top_item(), to=lid_loc)\n",
    "        moved_lid = True\n",
    "        # now there should be no lid on this item\n",
    "    if isinstance(media_stack.get_top_item(), Lid):\n",
    "        raise ValueError('Too many lids on Stack to refill media')\n",
    "    for j in range(1, 13):\n",
    "        for i in range(8):\n",
    "            media_stack.get_top_item()[f'{cptl_alphabet[i]}{j}'][0].tracker.set_liquids([(\"media\", 2000)])\n",
    "    # if moved_lid:\n",
    "    #     await lh.move_lid(lid=lid_loc.get_top_item(), to=media_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def empty_waste(wash):\n",
    "    for j in range(1, 13):\n",
    "        for i in range(8):\n",
    "            # Using the f-string allows us to iterate through \n",
    "            # wells A1 -> B1 -> C1 -> ... -> H1\n",
    "            # all in one line of code!\n",
    "            wash['A1'][0].tracker.set_liquids([(\"media\", 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Main Robot Method to Follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def turb_main_loop(cycles):\n",
    "    # --------------------------------\n",
    "    # FLAGS/system settings\n",
    "    is_simulated_plate_reader_data = True\n",
    "    # TODO: make this a system argument -> flag\n",
    "    std_slope = 0.252\n",
    "    std_intercept = 0.089\n",
    "    well_volume = 150   # µL\n",
    "\n",
    "    # colums without any colonies (starting from left)\n",
    "    # in final program will be flag set to zero unless otherwise noted \n",
    "    cols_of_none = 0\n",
    "\n",
    "    max_well_volume = 350\n",
    "\n",
    "    file_out_for_plate_reader = 'data.csv'\n",
    "\n",
    "    setpoint = 0.7\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # TODO\n",
    "    # REMEMBER TO INSTANTIALIZE & CLEAR THE DB SESSION, OR IMPORT IT HERE!\n",
    "    # currently done earlier in ipynb, make into method and plate here\n",
    "\n",
    "    # --------------------------------\n",
    "    data_sim = DataSimulator(session=session, rand_nor_mean=1, rand_nor_std=0.05)\n",
    "\n",
    "    plate_reader = PlateReader(is_sim=is_simulated_plate_reader_data,\n",
    "                            output_file=file_out_for_plate_reader, session=session, data_sim=data_sim)\n",
    "\n",
    "\n",
    "    lh = await setup_lh()\n",
    "    idx = 0\n",
    "    tip_racks, wash, media_plates, culture_plates = await deck_setup(lh=lh)\n",
    "    media_stacks, culture_stacks = setup_stacks(media_plates=media_plates, culture_plates=culture_plates, lh=lh)   \n",
    "\n",
    "    # adding plates do DB\n",
    "    for plate in culture_plates:\n",
    "        db_add_plate(session=session, plate=plate)\n",
    "        db_add_wells_from_plate(session=session, plate_name=plate.name)\n",
    "\n",
    "\n",
    "    num_plates = len(culture_plates)\n",
    "    num_media_plates = len(media_plates)\n",
    "\n",
    "    max_transfer_frac = (max_well_volume - well_volume) / max_well_volume\n",
    "\n",
    "    turb_controllers = [DiagnosticPIDTurbController(setpoint=setpoint, init_od=1e-6, output_limits=(0, max_transfer_frac), db_session=session) for i in range(96*num_plates)]\n",
    "    turb_controller_batches = []\n",
    "    for i in range(num_plates): \n",
    "        turb_controller_batches.append(turb_controllers[i*96:(i+1)*96])\n",
    "\n",
    "\n",
    "    # continued turbidostat\n",
    "    while idx < cycles:\n",
    "        cycle_idx = idx % num_plates\n",
    "\n",
    "        tip_rack = tip_racks[cycle_idx]\n",
    "        plate_stack = culture_stacks[cycle_idx]\n",
    "        plate_lid_loc = culture_stacks[(idx + 1) % num_plates]\n",
    "\n",
    "        # TODO: configure testing to switch when media plate wells are below max_transfer_vol?\n",
    "        media_stack = media_stacks[idx % num_media_plates]\n",
    "        media_lid_loc = media_stacks[(idx + 1) % num_media_plates]\n",
    "\n",
    "        turb_controller_batch = turb_controller_batches[cycle_idx]\n",
    "        plate_data = read_plate(plate_stack=plate_stack, plate_reader=plate_reader, is_sim=is_simulated_plate_reader_data)\n",
    "\n",
    "        replacement_fractions = calculate_replacement_volumes(turb_controller_batch, plate_data, std_slope, std_intercept, well_volume=well_volume, cols_of_none=cols_of_none, max_well_volume=max_well_volume)\n",
    "\n",
    "\n",
    "        for count, (od, controller) in enumerate(zip(plate_data, turb_controller_batch)):\n",
    "            fraction = max(0.0, replacement_fractions[count])\n",
    "\n",
    "            k_est = controller.estimated_growth_rate\n",
    "\n",
    "            row_index = count % 8        # rows A-H (in numerical form)\n",
    "            col_index = (count // 8) + 1 # columns 1-12\n",
    "\n",
    "            db_add_reading(\n",
    "                session=session,\n",
    "                reading=(od, k_est, fraction),\n",
    "                well_row=row_index,\n",
    "                well_col=col_index,\n",
    "                plate_name=plate_stack.children[0].name  # if using plain plate, use plate.name = \"culture_plate_0\"\n",
    "            )\n",
    "        \n",
    "        await dilute_96w_plate(cycle_idx, well_volume*replacement_fractions, lh=lh, media_lid_loc=media_lid_loc, plate_lid_loc=plate_lid_loc, cols_of_none=cols_of_none, tip_rack=tip_rack, plate_stack=plate_stack, media_stack=media_stack, wash=wash)\n",
    "\n",
    "        # TODO: insert if statement regarding when to refill media\n",
    "        await refill_media(media_stack=media_stack, lh=lh, lid_loc=media_lid_loc)\n",
    "        \n",
    "        # TODO: insert if statement regarding when to empty waste\n",
    "        await empty_waste(wash=wash)\n",
    "        # TODO: do multithreading\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "await turb_main_loop(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Graph data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Connect to your local SQLite database\n",
    "conn = sqlite3.connect(\"turbidostat.db\")\n",
    "\n",
    "# Query joined data from the readings, wells, and plates\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  plates.name AS plate_name,\n",
    "  wells.row,\n",
    "  wells.col,\n",
    "  readings.timestamp,\n",
    "  readings.od\n",
    "FROM readings\n",
    "JOIN plates ON readings.plate_id = plates.id\n",
    "JOIN wells ON readings.well_id = wells.id\n",
    "ORDER BY readings.timestamp\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "df[\"time\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df[\"col\"] = df[\"col\"].astype(int)\n",
    "df[\"well\"] = df[\"row\"] + df[\"col\"].astype(str)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('od_sim_plots', exist_ok=True)\n",
    "directory = 'od_sim_plots'\n",
    "existing_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "plot_count = len(existing_files)\n",
    "\n",
    "# Define rows and columns for plate layout\n",
    "rows = \"ABCDEFGH\"\n",
    "cols = range(1, 13)\n",
    "\n",
    "df.to_csv('sim_data_df_from_query.csv')\n",
    "\n",
    "# Group data by plate name and plot each separately\n",
    "for plate_index, (plate_name, plate_df) in enumerate(df.groupby(\"plate_name\")):\n",
    "    fig, axes = plt.subplots(8, 12, figsize=(24, 16), sharex=True, sharey=True)\n",
    "    fig.suptitle(f\"OD Over Time per Well — Plate: {plate_name}\", fontsize=18)\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, col in enumerate(cols):\n",
    "            ax = axes[i, j]\n",
    "            well_id = f\"{row}{col}\"\n",
    "            well_df = plate_df[(plate_df[\"row\"] == row) & (plate_df[\"col\"] == col)]\n",
    "\n",
    "            if not well_df.empty:\n",
    "                ax.plot(well_df[\"time\"], well_df[\"od\"], linestyle='-', linewidth=1)\n",
    "                ax.set_ylim(0,1.0)\n",
    "\n",
    "            ax.set_title(well_id, fontsize=8)\n",
    "            ax.tick_params(labelsize=6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    filename = f\"{directory}/sim_attempt_{plot_count + plate_index + 1}_{plate_name}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Seaborn style\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Connect to your local SQLite database\n",
    "conn = sqlite3.connect(\"turbidostat.db\")\n",
    "\n",
    "# Query joined data from the readings, wells, and plates\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  plates.name AS plate_name,\n",
    "  wells.row,\n",
    "  wells.col,\n",
    "  readings.timestamp,\n",
    "  readings.od\n",
    "FROM readings\n",
    "JOIN plates ON readings.plate_id = plates.id\n",
    "JOIN wells ON readings.well_id = wells.id\n",
    "ORDER BY readings.timestamp\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "df[\"time\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df[\"col\"] = df[\"col\"].astype(int)\n",
    "df[\"well\"] = df[\"row\"] + df[\"col\"].astype(str)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('od_sim_plots', exist_ok=True)\n",
    "directory = 'od_sim_plots'\n",
    "existing_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "plot_count = len(existing_files)\n",
    "\n",
    "# Define rows and columns for plate layout\n",
    "rows = \"ABCDEFGH\"\n",
    "cols = range(1, 13)\n",
    "\n",
    "df.to_csv('sim_data_df_from_query.csv', index=False)\n",
    "\n",
    "# Group data by plate name and plot each separately\n",
    "for plate_index, (plate_name, plate_df) in enumerate(df.groupby(\"plate_name\")):\n",
    "    fig, axes = plt.subplots(8, 12, figsize=(24, 16), sharex=True, sharey=True)\n",
    "    fig.suptitle(f\"OD Over Time per Well — Plate: {plate_name}\", fontsize=18)\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, col in enumerate(cols):\n",
    "            ax = axes[i, j]\n",
    "            well_df = plate_df[(plate_df[\"row\"] == row) & (plate_df[\"col\"] == col)]\n",
    "\n",
    "            if not well_df.empty:\n",
    "                sns.lineplot(data=well_df, x=\"time\", y=\"od\", ax=ax, linewidth=1)\n",
    "                ax.set_ylim(0, 1.0)\n",
    "\n",
    "            ax.set_title(f\"{row}{col}\", fontsize=8)\n",
    "            ax.tick_params(labelsize=6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    filename = f\"{directory}/sim_attempt_{plot_count + plate_index + 1}_{plate_name}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
